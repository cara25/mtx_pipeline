{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9144364d-8e6b-400f-8ccf-7e2b38360252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV, LogisticRegressionCV\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, mean_squared_error, r2_score, \\\n",
    "roc_curve, auc, precision_score, recall_score, confusion_matrix, precision_recall_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e28e54-ad57-477f-945f-c8a5dc866f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUTS #\n",
    "seed = 42\n",
    "splits = 10 # from what we decided\n",
    "protein_type = 'log' # make equal to 'linear' or 'log' and variables will update accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed83d7bf-7818-4dc2-a064-67ae0f24eb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Navigate back one directory to retrieve CSV files\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "data_dir = os.path.join(parent_dir, 'datasets')\n",
    "\n",
    "# Initialize lists to store data splits\n",
    "X_train_list, X_test_list = [], []\n",
    "y_train_list, y_test_list = [], [] # same response variables no matter the X transformation\n",
    "\n",
    "# Iterate over each split index\n",
    "for i in range(1, splits + 1):\n",
    "    if protein_type == 'linear':\n",
    "        prot_train_path = f'train_{i}.csv'\n",
    "        prot_test_path = f'test_{i}.csv'\n",
    "    elif protein_type == 'log':\n",
    "        prot_train_path = f'log_train_{i}.csv'\n",
    "        prot_test_path = f'log_test_{i}.csv'\n",
    "    train_file = os.path.join(data_dir, prot_train_path)\n",
    "    test_file = os.path.join(data_dir, prot_test_path)\n",
    "\n",
    "    # Read training data and split into X_train and y_train\n",
    "    train_df = pd.read_csv(train_file)\n",
    "    X_train = train_df.drop(columns=['mtx_binary', 'Unnamed: 0', 'EAC_ID'])\n",
    "    y_train = train_df['mtx_binary']\n",
    "    \n",
    "    # Read test data and split into X_test and y_test\n",
    "    test_df = pd.read_csv(test_file)\n",
    "    X_test = test_df.drop(columns=['mtx_binary', 'Unnamed: 0', 'EAC_ID'])\n",
    "    y_test = test_df['mtx_binary']\n",
    "    \n",
    "    # Append to respective lists\n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    y_train_list.append(y_train)\n",
    "    y_test_list.append(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19ba6226-d47f-4157-9202-59e5169815bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import full data as well\n",
    "# write paths here\n",
    "data_path = \"/Users/chang.cara/Desktop/proteomics/proteomics_merged.csv\"\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "data = data.drop(columns=[\"Unnamed: 0\"])\n",
    "\n",
    "\n",
    "# subset based on proteomics\n",
    "if protein_type == 'linear':\n",
    "    protein_cols = [x for x in data.columns.to_list() if 'linear_UniProt' in x]\n",
    "elif protein_type == 'log':\n",
    "    protein_cols = [x for x in data.columns.to_list() if 'UniProt' in x and 'linear_UniProt' not in x]\n",
    "protein_cols.insert(0, \"mtx_binary\") # include the response variables\n",
    "\n",
    "proteins = data[protein_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5f426ad-cd29-4b7c-80d3-515eedd806d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create helper functions to process and retrieve feature subsets\n",
    "def lasso_train_pred(X_train, y_train, X_test, y_test, random_state=seed):\n",
    "    # A list of possible C values (lambda), and this finds the optimal lambda\n",
    "    Cs = np.logspace(-1, 1)\n",
    "    # L1 penalty makes it lambda\n",
    "    model_cv = LogisticRegressionCV(Cs=Cs, cv=10, penalty='l1', solver='liblinear', random_state=random_state)\n",
    "    model_cv.fit(X_train, y_train)\n",
    "    # Uses the best lambda now\n",
    "    best_lambda = model_cv.C_[0]\n",
    "    # Using the developed lasso model to predict on test data\n",
    "    model = LogisticRegression(penalty='l1', C=best_lambda, solver='liblinear', random_state=random_state)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities on test data\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    return model, y_pred_proba, best_lambda, model_cv\n",
    "\n",
    "def calc_roc_auc(y_test, y_pred_proba):\n",
    "    # Calculate ROC-AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return roc_auc\n",
    "\n",
    "def non_zero_feats(X_train, X_test, model):\n",
    "    # Identify non-zero coefficients\n",
    "    non_zero_coefs = model.coef_[0] != 0\n",
    "    selected_features = X_train.columns[non_zero_coefs]\n",
    "    \n",
    "    # Subset the original DataFrame to include only the selected features\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = X_test[selected_features]\n",
    "    \n",
    "    # Print shape of the subset data\n",
    "    print(\"Number of features:\", X_train_selected.shape[1])\n",
    "    return X_train_selected, X_test_selected, selected_features\n",
    "\n",
    "# Function to process each fold, print results, and generate plot\n",
    "def process_fold(X_train, y_train, X_test, y_test, i, random_state=42):\n",
    "    model, y_pred_proba, best_lambda, model_cv = lasso_train_pred(X_train, y_train, X_test, y_test)\n",
    "    roc_auc = calc_roc_auc(y_test, y_pred_proba)\n",
    "    \n",
    "    X_train_selected, X_test_selected, selected_features = non_zero_feats(X_train, X_test, model)\n",
    "\n",
    "    return model, roc_auc, X_train_selected, X_test_selected, selected_features, best_lambda\n",
    "\n",
    "# Ensure the output directory exists\n",
    "# Constructing a directory path using os.path.join() with the string\n",
    "output_dir = os.path.join(protein_type, 'lasso_subsets')\n",
    "\n",
    "# Ensure the directory exists, create if it doesn't\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "245dfeef-d93f-4cc1-a1a3-350c3e4b027c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n",
      "Number of features: 32\n",
      "ROC AUC:  0.4444444444444444\n",
      "Optimal lambda:  0.3393221771895328\n",
      "Split 2\n",
      "Number of features: 13\n",
      "ROC AUC:  0.33333333333333337\n",
      "Optimal lambda:  0.1\n",
      "Split 3\n",
      "Number of features: 15\n",
      "ROC AUC:  1.0\n",
      "Optimal lambda:  0.1\n",
      "Split 4\n",
      "Number of features: 40\n",
      "ROC AUC:  0.25\n",
      "Optimal lambda:  0.6551285568595507\n",
      "Split 5\n",
      "Number of features: 17\n",
      "ROC AUC:  0.125\n",
      "Optimal lambda:  0.12067926406393285\n",
      "Split 6\n",
      "Number of features: 16\n",
      "ROC AUC:  0.5\n",
      "Optimal lambda:  0.1\n",
      "Split 7\n",
      "Number of features: 32\n",
      "ROC AUC:  0.375\n",
      "Optimal lambda:  0.372759372031494\n",
      "Split 8\n",
      "Number of features: 46\n",
      "ROC AUC:  0.5\n",
      "Optimal lambda:  5.17947467923121\n",
      "Split 9\n",
      "Number of features: 20\n",
      "ROC AUC:  0.875\n",
      "Optimal lambda:  0.10985411419875583\n",
      "Split 10\n",
      "Number of features: 49\n",
      "ROC AUC:  0.625\n",
      "Optimal lambda:  8.286427728546842\n",
      "Mean AUC:  0.5027777777777778\n"
     ]
    }
   ],
   "source": [
    "selected_features_list = []\n",
    "auc_list = []\n",
    "\n",
    "# Perform on the folds\n",
    "for i in range(1, splits + 1):\n",
    "    X_train = X_train_list[i - 1]\n",
    "    X_test = X_test_list[i - 1]\n",
    "    y_train = y_train_list[i - 1]\n",
    "    y_test = y_test_list[i - 1]\n",
    "\n",
    "    print(f\"Split {i}\")\n",
    "    model, roc_auc_lasso, X_train_selected, X_test_selected, selected_features, best_lambda = process_fold(X_train, y_train, X_test, y_test, i)\n",
    "    print(\"ROC AUC: \", roc_auc_lasso)\n",
    "    auc_list.append(roc_auc_lasso)\n",
    "    print(\"Optimal lambda: \", best_lambda)\n",
    "    selected_features_list.append(list(selected_features))\n",
    "    # Write train and test subsets to CSV files\n",
    "    X_train_selected.to_csv(os.path.join(output_dir, f'train_selected_{i}.csv'), index=False)\n",
    "    X_test_selected.to_csv(os.path.join(output_dir, f'test_selected_{i}.csv'), index=False)\n",
    "\n",
    "# Report avg AUC and accuracy for different fold numbers\n",
    "print(\"Mean AUC: \", np.mean(auc_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dab4ee1-d3fb-4433-adaa-e5d1f60f7374",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_feat_sel_list = [\n",
    "    x\n",
    "    for xs in selected_features_list\n",
    "    for x in xs\n",
    "]\n",
    "\n",
    "feat_dict = {x:0 for x in flat_feat_sel_list}\n",
    "for x in flat_feat_sel_list:\n",
    "    feat_dict[x] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "883071ef-d52b-4736-8427-8600a0af83cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UniProtB6A8C7#TARM1OID30937': 4,\n",
       " 'UniProtO00337#SLC28A1OID31220': 6,\n",
       " 'UniProtO15212#PFDN6OID30938': 5,\n",
       " 'UniProtO15263#DEFB4A_DEFB4BOID21373': 7,\n",
       " 'UniProtO43422#THAP12OID31238': 4,\n",
       " 'UniProtP01241#GH1OID20220': 5,\n",
       " 'UniProtP01275#GCGOID21263': 3,\n",
       " 'UniProtP03372#ESR1OID30434': 7,\n",
       " 'UniProtP05112#IL4OID20426': 6,\n",
       " 'UniProtP05113#IL5OID20472': 4,\n",
       " 'UniProtP08908#HTR1AOID30824': 8,\n",
       " 'UniProtP0CG30#GSTT2BOID31097': 3,\n",
       " 'UniProtP14649#MYL6BOID30936': 5,\n",
       " 'UniProtP16442#ABOOID30675': 10,\n",
       " 'UniProtP23435#CBLN1OID30851': 8,\n",
       " 'UniProtP31371#FGF9OID31193': 7,\n",
       " 'UniProtP34910#EVI2BOID31227': 5,\n",
       " 'UniProtP36897#TGFBR1OID30502': 4,\n",
       " 'UniProtP41439#FOLR3OID21485': 10,\n",
       " 'UniProtP49662#CASP4OID31276': 8,\n",
       " 'UniProtP50897#PPT1OID30947': 2,\n",
       " 'UniProtP51460#INSL3OID31129': 7,\n",
       " 'UniProtP54317#PNLIPRP2OID20775': 10,\n",
       " 'UniProtP80098#CCL7OID20523': 3,\n",
       " 'UniProtQ16520#BATFOID30896': 4,\n",
       " 'UniProtQ5SXM8#DNLZOID30822': 6,\n",
       " 'UniProtQ5VT06#CEP350OID31247': 7,\n",
       " 'UniProtQ6PH85#DCUN1D2OID31231': 4,\n",
       " 'UniProtQ8N907#DAND5OID30420': 1,\n",
       " 'UniProtQ8WXG9#ADGRV1OID30877': 6,\n",
       " 'UniProtQ9UKR0#KLK12OID21201': 2,\n",
       " 'UniProtQ9Y3B9#RRP15OID30867': 1,\n",
       " 'UniProtO43653#PSCAOID31493': 8,\n",
       " 'UniProtQ5T871#LELP1OID30845': 3,\n",
       " 'UniProtQ7Z7H5#TMED4OID30154': 2,\n",
       " 'UniProtQ9NY46#SCN3AOID30903': 8,\n",
       " 'UniProtP19429#TNNI3OID20050': 6,\n",
       " 'UniProtO14503#BHLHE40OID30873': 3,\n",
       " 'UniProtP10636#MAPTOID20830': 1,\n",
       " 'UniProtP10746#UROSOID30964': 2,\n",
       " 'UniProtP16860#NPPBOID20049': 3,\n",
       " 'UniProtP29353#SHC1OID31222': 2,\n",
       " 'UniProtP29459_P29460#IL12A_IL12BOID21327': 1,\n",
       " 'UniProtP50461#CSRP3OID30176': 4,\n",
       " 'UniProtP51815#ZNF75DOID31303': 3,\n",
       " 'UniProtQ14627#IL13RA2OID30841': 6,\n",
       " 'UniProtQ14894#CRYMOID30815': 2,\n",
       " 'UniProtQ5VT99#LRRC38OID30924': 3,\n",
       " 'UniProtQ6P5Q4#LMOD2OID30864': 3,\n",
       " 'UniProtQ86WK6#AMIGO1OID30881': 2,\n",
       " 'UniProtQ8IU54#IFNL1OID20795': 5,\n",
       " 'UniProtQ96IW2#SHDOID30098': 2,\n",
       " 'UniProtP10645#CHGAOID30403': 2,\n",
       " 'UniProtP49223#SPINT3OID31509': 1,\n",
       " 'UniProtQ6GTS8#PM20D1OID20149': 1,\n",
       " 'UniProtP35556#FBN2OID30974': 1,\n",
       " 'UniProtO75312#ZPR1OID30801': 1,\n",
       " 'UniProtP13385#TDGF1OID20816': 1,\n",
       " 'UniProtP26441#CNTFOID30807': 1,\n",
       " 'UniProtP36952#SERPINB5OID20064': 1,\n",
       " 'UniProtP43632#KIR2DS4OID31432': 1,\n",
       " 'UniProtQ29980_Q29983#MICB_MICAOID20593': 3,\n",
       " 'UniProtQ99795#GPA33OID21376': 1,\n",
       " 'UniProtO00401#WASLOID30467': 1,\n",
       " 'UniProtO15350#TP73OID30879': 1,\n",
       " 'UniProtO43524#FOXO3OID21271': 2,\n",
       " 'UniProtO95049#TJP3OID30798': 1,\n",
       " 'UniProtO95670#ATP6V1G2OID30167': 1,\n",
       " 'UniProtP02652#APOA2OID30686': 1,\n",
       " 'UniProtP09172#DBHOID30703': 1,\n",
       " 'UniProtP09466#PAEPOID20925': 1,\n",
       " 'UniProtP0DML2#CSH1OID30667': 2,\n",
       " 'UniProtP11310#ACADMOID31277': 2,\n",
       " 'UniProtQ04609#FOLH1OID30430': 1,\n",
       " 'UniProtQ14184#DOC2BOID30927': 2,\n",
       " 'UniProtQ3B7J2#GFOD2OID21216': 1,\n",
       " 'UniProtP27701#CD82OID31256': 1,\n",
       " 'UniProtO00534#VWA5AOID31198': 1,\n",
       " 'UniProtP59282#TPPP2OID31274': 1,\n",
       " 'UniProtP63010#AP2B1OID30949': 1,\n",
       " 'UniProtQ10571#MN1OID30908': 1,\n",
       " 'UniProtQ16650#TBR1OID30923': 1,\n",
       " 'UniProtQ8NET8#TRPV3OID30128': 1,\n",
       " 'UniProtQ93062#RBPMSOID30507': 1}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e511be4-6420-4365-977c-9bbab58d8ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Num_Occurrences</th>\n",
       "      <th>Missing_Splits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UniProtP41439#FOLR3OID21485</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UniProtP16442#ABOOID30675</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>UniProtP54317#PNLIPRP2OID20775</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UniProtP08908#HTR1AOID30824</td>\n",
       "      <td>8</td>\n",
       "      <td>Split 2, Split 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>UniProtQ9NY46#SCN3AOID30903</td>\n",
       "      <td>8</td>\n",
       "      <td>Split 1, Split 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>UniProtP49223#SPINT3OID31509</td>\n",
       "      <td>1</td>\n",
       "      <td>Split 1, Split 2, Split 3, Split 4, Split 6, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UniProtP10636#MAPTOID20830</td>\n",
       "      <td>1</td>\n",
       "      <td>Split 1, Split 2, Split 3, Split 5, Split 6, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>UniProtQ9Y3B9#RRP15OID30867</td>\n",
       "      <td>1</td>\n",
       "      <td>Split 2, Split 3, Split 4, Split 5, Split 6, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>UniProtQ8N907#DAND5OID30420</td>\n",
       "      <td>1</td>\n",
       "      <td>Split 2, Split 3, Split 4, Split 5, Split 6, S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>UniProtQ93062#RBPMSOID30507</td>\n",
       "      <td>1</td>\n",
       "      <td>Split 1, Split 2, Split 3, Split 4, Split 5, S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Feature  Num_Occurrences  \\\n",
       "18     UniProtP41439#FOLR3OID21485               10   \n",
       "13       UniProtP16442#ABOOID30675               10   \n",
       "22  UniProtP54317#PNLIPRP2OID20775               10   \n",
       "10     UniProtP08908#HTR1AOID30824                8   \n",
       "35     UniProtQ9NY46#SCN3AOID30903                8   \n",
       "..                             ...              ...   \n",
       "53    UniProtP49223#SPINT3OID31509                1   \n",
       "38      UniProtP10636#MAPTOID20830                1   \n",
       "31     UniProtQ9Y3B9#RRP15OID30867                1   \n",
       "28     UniProtQ8N907#DAND5OID30420                1   \n",
       "83     UniProtQ93062#RBPMSOID30507                1   \n",
       "\n",
       "                                       Missing_Splits  \n",
       "18                                               None  \n",
       "13                                               None  \n",
       "22                                               None  \n",
       "10                                   Split 2, Split 5  \n",
       "35                                   Split 1, Split 7  \n",
       "..                                                ...  \n",
       "53  Split 1, Split 2, Split 3, Split 4, Split 6, S...  \n",
       "38  Split 1, Split 2, Split 3, Split 5, Split 6, S...  \n",
       "31  Split 2, Split 3, Split 4, Split 5, Split 6, S...  \n",
       "28  Split 2, Split 3, Split 4, Split 5, Split 6, S...  \n",
       "83  Split 1, Split 2, Split 3, Split 4, Split 5, S...  \n",
       "\n",
       "[84 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_selected_list = []\n",
    "for i in range(splits):\n",
    "    if protein_type == \"linear\":\n",
    "        X_train_selected_list.append(pd.read_csv(f'linear/lasso_subsets/train_selected_{i+1}.csv'))\n",
    "    elif protein_type == \"log\":\n",
    "        X_train_selected_list.append(pd.read_csv(f'log/lasso_subsets/train_selected_{i+1}.csv'))\n",
    "\n",
    "# Dictionary to store the number of splits each feature is missing from\n",
    "missing_splits_dict = {feature: [] for feature in feat_dict.keys()}\n",
    "\n",
    "# Update the occurrence and missing splits for each feature\n",
    "for i, X_train_selected in enumerate(X_train_selected_list):\n",
    "    current_features = X_train_selected.columns\n",
    "    for feature in feat_dict.keys():\n",
    "        if feature not in current_features:\n",
    "            missing_splits_dict[feature].append(f'Split {i+1}')\n",
    "\n",
    "# Create a dataframe to store the result\n",
    "results = []\n",
    "for feature, num_occurrences in feat_dict.items():\n",
    "    missing_splits = missing_splits_dict[feature]\n",
    "    if not missing_splits:\n",
    "        missing_splits = 'None'\n",
    "    else:\n",
    "        missing_splits = ', '.join(missing_splits)\n",
    "    results.append([feature, num_occurrences, missing_splits])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=['Feature', 'Num_Occurrences', 'Missing_Splits'])\n",
    "results_df = results_df.sort_values(by='Num_Occurrences', ascending=False)\n",
    "\n",
    "results_df.to_csv(os.path.join(output_dir, 'feature_occurrences.csv'), index=False)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8ff954-70cf-46cb-9ed9-a0fa33152cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
