{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0c93852-e5e0-46b7-96c1-7c70d71c91df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "396a7ed5-58f2-4c1b-920b-738a21c588ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write paths here\n",
    "patient_path = os.path.join(\"..\",\"raw\",\"RA_mtx_patient_info.tsv\")\n",
    "bridge_path = os.path.join(\"..\",\"raw\",\"Parent_Child_Bridge_info.csv\")\n",
    "olink_path = os.path.join(\"..\",\"raw\",\"Q-04911_Sung_NPX_2023-02-24.csv\")\n",
    "metabolomics_path = os.path.join(\"..\",\"raw\",\"metabolon_raw_norm_preprocessed.tsv\")\n",
    "metabolomics_bridge = os.path.join(\"..\",\"raw\",\"RA_MTX_CLP_GLOBAL_PROFILE_child_parentID_Aug1.xlsx\")\n",
    "\n",
    "# load patient data\n",
    "patients = pd.read_csv(patient_path, sep=\"\\t\")\n",
    "# load bridge file\n",
    "bridge = pd.read_csv(bridge_path)\n",
    "# load olink data\n",
    "olink = pd.read_csv(olink_path, sep=\";\")\n",
    "# load metabolomics\n",
    "metabolomics = pd.read_csv(metabolomics_path, delimiter='\\t').T\n",
    "metabolomics_bridge = pd.read_excel(metabolomics_bridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac86fbb9-34b3-4753-8ac3-46429a583473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing and merging\n",
    "#patients.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc738dea-a28f-444f-b19c-e061a76affd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#olink[olink[\"NPX\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6358daa0-5acf-4111-8516-70acd00a35d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#olink.head()\n",
    "#olinkId + UniProt + Assay represents 1 protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "303ae8c0-789c-4dd1-baf5-a8d45aaeb633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make one protein ID col combining UniProt, and Assay\n",
    "olink[\"ProteinID\"] = \"UniProt\" + olink[\"UniProt\"].astype(str) + \"#\" + olink[\"Assay\"].astype(str) + olink[\"OlinkID\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2748c8ce-88a3-476c-9f6a-173d11c99ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2944"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(olink[\"ProteinID\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eccdaba6-cd43-4165-a7c0-50fbf1b285da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = ~olink['SampleID'].str.contains(\"CONTROL\")\n",
    "olink = olink.loc[mask] # filters out the control prevalences that are just for Olink program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db40457d-0370-409b-99ef-ee550a96bacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#olink.loc[olink[\"ProteinID\"] == \"UniProtA2VDF0#FUOMOID30626\"] # check why this one had nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a31f4fd-fb83-4623-a7e0-8074fcf96f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#olink[olink[\"NPX\"] == 0] # check why some NPX are 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc8dd46f-2ad0-485e-bfb0-d366bd76ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pivot the data to all be on the sample level instead of protein by protein\n",
    "proteins = olink[['SampleID', 'ProteinID', 'NPX']].pivot(index='SampleID', columns='ProteinID', values='NPX').reset_index()\n",
    "proteins = proteins.dropna(axis=1)\n",
    "#proteins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce84854b-bfdb-452c-817a-92727ae8bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to hold new columns\n",
    "new_cols_dict = {}\n",
    "\n",
    "# function to linearize the log base 2 data\n",
    "def log2_to_linear(x):\n",
    "    return 2 ** x\n",
    "\n",
    "# Convert Log2 NPX to linear scale and store in dictionary\n",
    "for col in proteins.columns:\n",
    "    if col.startswith('UniProt'):\n",
    "        linear_col_name = 'linear_' + col\n",
    "        new_cols_dict[linear_col_name] = proteins[col].apply(log2_to_linear)\n",
    "\n",
    "# Create a new DataFrame from the dictionary\n",
    "new_cols_df = pd.DataFrame(new_cols_dict)\n",
    "\n",
    "# Concatenate the new columns with the original DataFrame\n",
    "proteins = pd.concat([proteins, new_cols_df], axis=1)\n",
    "\n",
    "# Define the order of the new columns\n",
    "new_cols = proteins.columns\n",
    "\n",
    "# Reorder columns if necessary\n",
    "proteins = proteins[new_cols]\n",
    "\n",
    "# Print the modified DataFrame to check\n",
    "#proteins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93712793-b806-498f-8195-5be18a0cefee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset patient data to Baseline and Plasma samples\n",
    "patients = patients.loc[(patients[\"visit\"]==\"P1V1\") & (patients[\"sample_type\"]==\"Plasma\")]\n",
    "# check that we got the original 60 patient visits\n",
    "patients.shape[0] == 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97c8cbe5-99bc-478f-af49-201463b448b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metabolomics = pd.read_csv(metabolomics_path, delimiter='\\t').T\n",
    "# Set the first row as the column names\n",
    "metabolomics.columns = metabolomics.iloc[0]\n",
    "metabolomics = metabolomics[1:]\n",
    "\n",
    "# reset index to be a new col for merge purposes\n",
    "metabolomics.reset_index(inplace=True)\n",
    "# name index as child_id\n",
    "metabolomics.rename(columns={'index': 'child_id'}, inplace=True)\n",
    "#metabolomics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a22c03e-08aa-4d63-9c0f-0fccffbd5969",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metabolomics_bridge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b5f7f05-11bc-4c30-81d4-4201855fffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the foreign key cols in both patients and olink using bridge dictionary\n",
    "bridge_dict = pd.Series(bridge[\"Child Sample Id\"].values, index=bridge[\"Parent Sample Id\"]).to_dict() # parent --> child\n",
    "# Convert the keys and values to integers, and remove any nan entries\n",
    "bridge_dict = {str(int(k)): str(int(v)) for k, v in bridge_dict.items() if not (pd.isna(k) or pd.isna(v))}\n",
    "# insert blank col\n",
    "patients.insert(1, \"child_id_prot\", '')\n",
    "# map to new values\n",
    "patients[\"child_id_prot\"] = patients[\"sample_id\"].map(bridge_dict)\n",
    "patients.rename(columns={\"sample_id\":\"parent_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86e65f3a-620b-446d-b89c-87b4b0e6293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for olink\n",
    "bridge_dict = pd.Series(bridge[\"Parent Sample Id\"].values, index=bridge[\"Child Sample Id\"]).to_dict() # child --> parent\n",
    "# Convert the keys and values to integers, and remove any nan entries\n",
    "bridge_dict = {str(int(k)): str(int(v)) for k, v in bridge_dict.items() if not (pd.isna(k) or pd.isna(v))}\n",
    "# insert blank col\n",
    "proteins.insert(1, \"parent_id\", '')\n",
    "# map to new values\n",
    "proteins[\"parent_id\"] = proteins[\"SampleID\"].map(bridge_dict)\n",
    "proteins.rename(columns={\"SampleID\":\"child_id_prot\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b29a9c0d-1cee-4acb-ba7a-90b3380615de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#proteins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec77ba48-50d3-4e45-8c07-dea4fbd4c50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the foreign key cols in both patients and metabolomics using bridge dictionary\n",
    "m_bridge_dict = pd.Series(metabolomics_bridge[\"Child Sample Id\"].values, index=metabolomics_bridge[\"Parent Sample Id\"]).to_dict() # parent --> child\n",
    "# Convert the keys and values to integers, and remove any nan entries\n",
    "m_bridge_dict = {str(int(k)): str(int(v)) for k, v in m_bridge_dict.items() if not (pd.isna(k) or pd.isna(v))}\n",
    "\n",
    "# insert blank col\n",
    "patients.insert(1, \"child_id_met\", '')\n",
    "# map to new values\n",
    "patients[\"child_id_met\"] = patients[\"parent_id\"].map(m_bridge_dict)\n",
    "patients.rename(columns={\"sample_id\":\"parent_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "770879e8-9c33-4e8e-b366-31984c867d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the metabolomics parent ID using the child ID\n",
    "m_bridge_dict = pd.Series(metabolomics_bridge[\"Parent Sample Id\"].values, index=metabolomics_bridge[\"Child Sample Id\"]).to_dict() # child --> parent\n",
    "# Convert the keys and values to integers, and remove any nan entries\n",
    "m_bridge_dict = {str(int(k)): str(int(v)) for k, v in m_bridge_dict.items() if not (pd.isna(k) or pd.isna(v))}\n",
    "\n",
    "# insert blank col\n",
    "metabolomics.insert(1, \"parent_id\", '')\n",
    "# map to new values\n",
    "metabolomics[\"parent_id\"] = metabolomics[\"child_id\"].map(m_bridge_dict)\n",
    "metabolomics.rename(columns={\"child_id\":\"child_id_met\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c9a7a079-a992-4bdc-8927-9dc8f5ebc07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to just the demographic cols of interest before merging #\n",
    "# create list of all to drop from merged metabolomics data\n",
    "#demo_cols_all = ['child_id', 'parent_id', 'mc_number', 'visit', 'sample_type', 'delta_visit', 'age', 'sex', 'calc_bmi', 'smoke_status', 'patient_global_assessment', 'accp', 'rheum_factor', 'esr', 'crp', 'physician_global_assesment', 'sjc28', 'tjc28', 'mtx_dose', 'mtx_units', 'mtx_freq', 'bsln_pred', 'dose_pred', 'freq_pred', 'visit_date', 'cdai', 'das28crp', 'disease_activity', 'flare_comorb___1', 'flare_comorb___2', 'flare_comorb___3', 'flare_comorb___4', 'flare_comorb___5', 'flare_comorb___6', 'flare_comorb___7', 'flare_comorb___8', 'flare_comorb___9', 'flare_comorb___10', 'race___1', 'race___2', 'race___3', 'race___4', 'race___5', 'race___6', 'race___7', 'race___8', 'patient_haq', 'general_comments_f_u', 'general_comments_bsl', 'comments_off', 'no_change_v2', 'note_mtx_issue', 'note_stool_issue', 'note_dmard_issue', 'note_misc_issue', 'note_consent', 'note_jcf']\n",
    "\n",
    "# the cols we want to include for demographic ML\n",
    "demo_cols_want = ['EAC_ID', 'child_id_met', 'child_id_prot', 'parent_id', 'mtx_response', 'age', 'sex', 'calc_bmi', 'smoke_status', 'accp', 'rheum_factor', 'das28crp']\n",
    "\n",
    "# subset the demographics\n",
    "# demo is this subset of patients\n",
    "# NOTE: if you want the full demographics, proceed using patients to merge instead of demo\n",
    "demo = patients[demo_cols_want]\n",
    "\n",
    "# change smoke_status to binary (1:never and 2:former --> 0:non-smoker, 3:smoker --> 1:smoker)\n",
    "demo.loc[demo[\"smoke_status\"] != 3.0, \"smoke_status\"] = 0\n",
    "demo.loc[demo[\"smoke_status\"] == 3.0, \"smoke_status\"] = 1\n",
    "# change accp and rheum_factor to binary (ordination doesn't change still, currently coded as 1s and 2s)\n",
    "demo.loc[demo[\"accp\"] == 1.0, \"accp\"] = 0\n",
    "demo.loc[demo[\"accp\"] == 2.0, \"accp\"] = 1\n",
    "demo.loc[demo[\"rheum_factor\"] == 1.0, \"rheum_factor\"] = 0\n",
    "demo.loc[demo[\"rheum_factor\"] == 2.0, \"rheum_factor\"] = 1\n",
    "\n",
    "#demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "884ac8a3-4412-4276-95ef-6af8a3be91e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EAC_ID           0\n",
       "child_id_met     0\n",
       "child_id_prot    0\n",
       "parent_id        0\n",
       "mtx_response     0\n",
       "age              0\n",
       "sex              0\n",
       "calc_bmi         1\n",
       "smoke_status     0\n",
       "accp             1\n",
       "rheum_factor     1\n",
       "das28crp         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for missing data\n",
    "demo.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9b40c6b-f5a8-423d-a265-b690834a41c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# impute missing values by median #\n",
    "calc_bmi_med = demo['calc_bmi'].median()\n",
    "accp_med = demo['accp'].median()\n",
    "rheum_factor_med = demo['rheum_factor'].median()\n",
    "\n",
    "no_accp = demo.loc[demo['accp'].isnull(), 'EAC_ID']\n",
    "no_calc_bmi = demo.loc[demo['calc_bmi'].isnull(), 'EAC_ID']\n",
    "no_rheum_factor = demo.loc[demo['rheum_factor'].isnull(), 'EAC_ID']\n",
    "\n",
    "demo.loc[demo['calc_bmi'].isnull(), 'calc_bmi'] = calc_bmi_med\n",
    "demo.loc[demo['accp'].isnull(), 'accp'] = accp_med\n",
    "demo.loc[demo['rheum_factor'].isnull(), 'rheum_factor'] = rheum_factor_med\n",
    "\n",
    "# UNCOMMENT TO SEE WHICH ARE MISSING\n",
    "#print('calc_bmi missing from idx ' + str(no_calc_bmi) + ' and imputed as ' + str(calc_bmi_med))\n",
    "#print('accp missing from idx ' + str(no_accp) + ' and imputed as ' + str(accp_med))\n",
    "#print('rheum_factor missing from idx ' + str(no_rheum_factor) + ' and imputed as ' + str(rheum_factor_med))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e8fdb0be-92ac-440b-b296-a7cb6c8449c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset to linear and log scale for proteomics\n",
    "linear_protein_cols = [x for x in proteins.columns.to_list() if 'linear_UniProt' in x] # linearized data\n",
    "log_protein_cols = [x for x in proteins.columns.to_list() if 'UniProt' in x and 'linear_UniProt' not in x] # original log2 data\n",
    "\n",
    "# keep id cols for merging\n",
    "also_keep_cols = [\"child_id_prot\", \"parent_id\"]\n",
    "\n",
    "linear_protein_cols = also_keep_cols + linear_protein_cols\n",
    "log_protein_cols = also_keep_cols + log_protein_cols\n",
    "\n",
    "linear_proteins = proteins[linear_protein_cols]\n",
    "log_proteins = proteins[log_protein_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67c24d30-a53e-4f4d-a395-41d82bf82730",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/dl/5lw3wzn54kg220nzcdqxsvt00000gr/T/ipykernel_9867/2254982004.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  demo.drop(\"mtx_response\", axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# create binary response col\n",
    "demo.insert(4, \"mtx_binary\", 0)\n",
    "demo.loc[demo[\"mtx_response\"] != \"none\", \"mtx_binary\"] = 1\n",
    "demo.drop(\"mtx_response\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47d93319-9fa0-4835-838b-76e000dc32e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge into one dataset\n",
    "# NOTE (same one again): if you want the full demographics, proceed using patients to merge instead of demo\n",
    "# additionally, would need to deal with missing vals after if using the whole set\n",
    "# like so (uncomment):\n",
    "# data = pd.merge(patients, proteins, on=\"child_id_prot\", how=\"left\")\n",
    "# data = pd.merge(data, metabolomics, on=\"child_id_met\", how=\"left\")\n",
    "\n",
    "# demographics + (LINEAR AND LOG) proteomics + metabolomics\n",
    "# This is just so everything is stored together\n",
    "data = pd.merge(demo, proteins, on=\"child_id_prot\", how=\"left\")\n",
    "data = pd.merge(data, metabolomics, on=\"child_id_met\", how=\"left\")\n",
    "\n",
    "# demographics + LINEAR proteomics + metabolomics\n",
    "linear_data = pd.merge(demo, linear_proteins, on=\"child_id_prot\", how=\"left\")\n",
    "linear_data = pd.merge(linear_data, metabolomics, on=\"child_id_met\", how=\"left\")\n",
    "\n",
    "# demographics + LOG proteomics + metabolomics\n",
    "log_data = pd.merge(demo, log_proteins, on=\"child_id_prot\", how=\"left\")\n",
    "log_data = pd.merge(log_data, metabolomics, on=\"child_id_met\", how=\"left\")\n",
    "\n",
    "# retrieve the child_ids that merge to subset to just baseline, used as intermediate tables\n",
    "child_id_prot = demo[[\"EAC_ID\", \"child_id_prot\", \"mtx_binary\"]] # used mainly to subset and include the response column\n",
    "child_id_met = demo[[\"EAC_ID\", \"child_id_met\", \"mtx_binary\"]]\n",
    "\n",
    "# proteins + metabolomics\n",
    "lin_prot_met = pd.merge(linear_proteins, metabolomics, on=\"parent_id\", how=\"left\")\n",
    "lin_prot_met = pd.merge(child_id_prot, lin_prot_met, on=\"child_id_prot\", how = \"left\")\n",
    "\n",
    "log_prot_met = pd.merge(log_proteins, metabolomics, on=\"parent_id\", how=\"left\")\n",
    "log_prot_met = pd.merge(child_id_prot, log_prot_met, on=\"child_id_prot\", how = \"left\")\n",
    "\n",
    "# demographics + proteins\n",
    "demo_lin_prot = pd.merge(demo, linear_proteins, on=\"child_id_prot\", how=\"left\")\n",
    "demo_log_prot = pd.merge(demo, log_proteins, on=\"child_id_prot\", how=\"left\")\n",
    "\n",
    "# demographics + metabolomics\n",
    "demo_met = pd.merge(demo, metabolomics, on=\"child_id_met\", how=\"left\")\n",
    "\n",
    "# JUST linear proteomics but adding mtx_binary\n",
    "linear_proteins = pd.merge(child_id_prot, linear_proteins, on=\"child_id_prot\", how = \"left\")\n",
    "# JUST log proteomics but adding mtx_binary\n",
    "log_proteins = pd.merge(child_id_prot, log_proteins, on=\"child_id_prot\", how = \"left\")\n",
    "# JUST metabolomics but adding mtx_binary\n",
    "metabolomics = pd.merge(child_id_met, metabolomics, on=\"child_id_met\", how = \"left\")\n",
    "\n",
    "# only 60 baseline obs and no missing values --> success\n",
    "# don't worry as much about number of cols because this changes with id cols and merging (check separately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd0b67d3-2c96-4137-aa63-ee74937b639d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the extra columns created in the merge\n",
    "data.drop(\"parent_id_y\", axis=1, inplace=True) # happens three times in here, make only one copy of parent_id\n",
    "data.drop(\"parent_id_x\", axis=1, inplace=True) # happens three times in here, make only one copy of parent_id\n",
    "# reorder so that both ids are by the front\n",
    "col_reorder_list = [x for x in data.columns.to_list() if x != \"parent_id\"]\n",
    "col_reorder_list.insert(1, \"parent_id\")\n",
    "data = data[col_reorder_list]\n",
    "\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "571f3f22-bb18-48d9-b2a8-86b9e75162a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE OUT #\n",
    "# Ensure the output directory exists to store the full datasets\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "output_dir = os.path.join(parent_dir, 'processed', 'full_data')\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56da0301-086b-471d-973c-e2a51ed43cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fully merged data ##\n",
    "# THIS INCLUDES:\n",
    "#   - Demographics: age, sex, calc_bmi*, smoke_status*, accp*, rheum_factor*, das28crp\n",
    "#   - BOTH: Linearized Proteomics AND Log2 Proteomics (cannot directly plug into ML, proteomics represented twice.)\n",
    "#   - Metabolomics\n",
    "data.to_csv(os.path.join(output_dir, \"proteomics_metabolomics_demographics_merged.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3b1773b-be67-4f53-b778-135627dac882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop unnecessary columns merged on/existing in rest of data\n",
    "# these ids exist in the merged data and can be remerged on EAC_ID (for validation purposes if needed)\n",
    "# only keeping EAC_ID, mtx_binary and dropping other ID columns\n",
    "# get rid of parent_id and child_id columns, does not get rid of EAC_ID because of caps\n",
    "\n",
    "def drop_parent_child_ids(df):\n",
    "    return df[[x for x in df.columns.to_list() if 'id' not in x]]\n",
    "\n",
    "# demo + linear prot + metabolomics\n",
    "linear_data = drop_parent_child_ids(linear_data)\n",
    "# demo + log prot + metabolomics\n",
    "log_data = drop_parent_child_ids(log_data)\n",
    "# linear prot + met\n",
    "lin_prot_met = drop_parent_child_ids(lin_prot_met)\n",
    "# log prot + met\n",
    "log_prot_met = drop_parent_child_ids(log_prot_met)\n",
    "# demo + linear prot\n",
    "demo_lin_prot = drop_parent_child_ids(demo_lin_prot)\n",
    "# demo + log prot\n",
    "demo_log_prot = drop_parent_child_ids(demo_log_prot)\n",
    "# demo + met\n",
    "demo_met = drop_parent_child_ids(demo_met)\n",
    "# linear prot\n",
    "linear_proteins = drop_parent_child_ids(linear_proteins)\n",
    "# log prot\n",
    "log_proteins = drop_parent_child_ids(log_proteins)\n",
    "# metabolomics\n",
    "metabolomics = drop_parent_child_ids(metabolomics)\n",
    "# demographics\n",
    "demo = drop_parent_child_ids(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2565999-7ba1-4ace-a143-9b906bbcc147",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23d8a081-894f-4e77-9747-b39158750224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e189e12d-2de1-4d91-8149-eda2a88f0f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lin_prot_met.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87a33495-0b05-4b05-a391-9c9480ab8b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_prot_met.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fcdedd52-8233-4903-b531-b267109a59fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo_lin_prot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d4b74bd-d3dc-4525-aa82-fa6622f03636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo_log_prot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "04f591e1-c8d7-4190-a9b4-adee06159236",
   "metadata": {},
   "outputs": [],
   "source": [
    "#demo_met.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2cd596b9-ed2e-4882-bf73-d00d861adf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear_proteins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e983e6d5-fcd6-4248-b5b5-253c4bcaf25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#log_proteins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75cb01f4-69ae-4df2-9163-d295602ec8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metabolomics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ccabee60-4e97-46bf-a7d2-4e26d403339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format: EACID + mtx_binary + data\n",
    "# This allows for splitting directly from here for ML purposes because mtx_binary is already stored in each dataset\n",
    "# ALL #\n",
    "# demo + linear prot + metabolomics\n",
    "linear_data.to_csv(os.path.join(output_dir, \"lin_proteomics_demographics_metabolomics.csv\"), index=False)\n",
    "# demo + log prot + metabolomics\n",
    "log_data.to_csv(os.path.join(output_dir, \"log_proteomics_demographics_metabolomics.csv\"), index=False)\n",
    "\n",
    "# PAIRWISE #\n",
    "# linear prot + met\n",
    "lin_prot_met.to_csv(os.path.join(output_dir, \"lin_proteomics_metabolomics.csv\"), index=False)\n",
    "# log prot + met\n",
    "log_prot_met.to_csv(os.path.join(output_dir, \"log_proteomics_metabolomics.csv\"), index=False)\n",
    "# demo + linear prot\n",
    "demo_lin_prot.to_csv(os.path.join(output_dir,\"lin_proteomics_demographics.csv\"), index=False)\n",
    "# demo + log prot\n",
    "demo_log_prot.to_csv(os.path.join(output_dir,\"log_proteomics_demographics.csv\"), index=False)\n",
    "# demo + met\n",
    "demo_met.to_csv(os.path.join(output_dir,\"demographics_metabolomics.csv\"), index=False)\n",
    "\n",
    "# SINGLE OMICS/DEMOGRAPHPICS #\n",
    "# linear prot\n",
    "linear_proteins.to_csv(os.path.join(output_dir, \"linear_proteins.csv\"), index=False)\n",
    "# log prot\n",
    "log_proteins.to_csv(os.path.join(output_dir, \"log_proteins.csv\"), index=False)\n",
    "# metabolomics\n",
    "metabolomics.to_csv(os.path.join(output_dir, \"metabolomics.csv\"), index=False)\n",
    "# demographics\n",
    "demo.to_csv(os.path.join(output_dir, \"demographics.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481839fe-c8ca-4b6c-962b-c906b699ad02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
